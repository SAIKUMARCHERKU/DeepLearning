{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc585491",
   "metadata": {},
   "source": [
    "**Neural Networks & Deep Learning: ICP_5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220f0751",
   "metadata": {},
   "source": [
    "**1. Implement Naïve Bayes method using scikit-learn library<br>\n",
    "Use dataset available with name glass<br>\n",
    "Use train_test_split to create training and testing part<br>\n",
    "Evaluate the model on test part using score and\n",
    "classification_report(y_true, y_pred)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "47e99e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  #Importing Libraries\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2660cc71",
   "metadata": {},
   "source": [
    "**Use dataset available with name glass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5cb728d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 10)\n"
     ]
    }
   ],
   "source": [
    "# Using dataset glass\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\cherk\\\\Downloads\\\\Deep learning\\\\ICP_5\\\\glass.csv\")\n",
    "print(data.shape)\n",
    "X_train, X_test = train_test_split(\n",
    "    data, test_size=0.2, random_state=int(time.time()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6de52",
   "metadata": {},
   "source": [
    "**Use train_test_split to create training and testing part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b1f70d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to create training and testing part\n",
    "features = [\n",
    "    \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac13a01",
   "metadata": {},
   "source": [
    "**Evaluate the model on test part using score and classification_report(y_true, y_pred)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7f0d6909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes\n",
      "Total number of points: 43\n",
      "Mislabeled points : 31\n",
      "Accuracy 27.91%\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.07      0.12        15\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.08      0.67      0.14         3\n",
      "           5       1.00      0.20      0.33         5\n",
      "           6       0.50      1.00      0.67         1\n",
      "           7       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.28        43\n",
      "   macro avg       0.51      0.49      0.38        43\n",
      "weighted avg       0.47      0.28      0.27        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on test part using score and classification_report(y_true, y_pred)\n",
    "\n",
    "gauss = GaussianNB()  # Naïve Bayes Classifier\n",
    "\n",
    "gauss.fit(\n",
    "    X_train[features].values,    # train classifier\n",
    "    X_train[\"Type\"]\n",
    ")\n",
    "# making predictions\n",
    "y_pred = gauss.predict(X_test[features])\n",
    "print(\"Naïve Bayes\\nTotal number of points: {}\\nMislabeled points : {}\\nAccuracy {:05.2f}%\"\n",
    "      .format(\n",
    "          X_test.shape[0],\n",
    "          (X_test[\"Type\"] != y_pred).sum(),\n",
    "          100 * (1 - (X_test[\"Type\"] != y_pred).sum() / X_test.shape[0])\n",
    "      ))\n",
    "print(\"\\n\")\n",
    "# Naïve Bayes Classifier performance\n",
    "# classification_report(y_true, y_pred)\n",
    "print(metrics.classification_report(X_test[\"Type\"], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8df1de2",
   "metadata": {},
   "source": [
    "**2. Implement linear SVM method using scikit library<br>\n",
    "Use the same dataset above<br>\n",
    "Use train_test_split to create training and testing part<br>\n",
    "Evaluate the model on test part using score and\n",
    "classification_report(y_true, y_pred)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "88a42e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM accuracy is: 69.77\n",
      "SVM RBF model accuracy is: 27.91\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.28      1.00      0.44        12\n",
      "           3       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.28        43\n",
      "   macro avg       0.05      0.17      0.07        43\n",
      "weighted avg       0.08      0.28      0.12        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LSV Classification\n",
    "svc_linear = SVC(kernel='linear')\n",
    "# train linear SVM model\n",
    "svc_linear.fit(\n",
    "    X_train[features].values,\n",
    "    X_train[\"Type\"]\n",
    ")\n",
    "Y_pred = svc_linear.predict(X_test[features])\n",
    "\n",
    "# Linear SVM Model performance\n",
    "acc_svc = round(svc_linear.score(\n",
    "    X_test[features].values, X_test[\"Type\"]) * 100, 2)\n",
    "print(\"Linear SVM accuracy is:\", acc_svc)\n",
    "# Support vector classifier (SVC) with the radial basis function kernel (RBF)\n",
    "svc_rbf = SVC(kernel='rbf')\n",
    "svc_rbf.fit(\n",
    "    X_train[features].values,\n",
    "    X_train[\"Type\"]\n",
    ")\n",
    "# model predictions\n",
    "Y_pred = svc_rbf.predict(X_test[features])\n",
    "# SVM RBF Model performance\n",
    "acc_svc = round(svc_rbf.score(\n",
    "    X_test[features].values, X_test[\"Type\"]) * 100, 2)\n",
    "print(\"SVM RBF model accuracy is:\", acc_svc)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(X_test[\"Type\"], Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c102d5d2",
   "metadata": {},
   "source": [
    "**Which algorithm you got better accuracy? Can you justify why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3577aee9",
   "metadata": {},
   "source": [
    "According to the above accuracy scores Naive Bayes method is best for data visualization than that of Support Vector\n",
    "Machine method. The performance of the each algorithm depends on several factors. So, few algorithms works well for only\n",
    "few of the problems and does not work well for other problems. By evaluating the model using various algorithms we can compare and then state which one is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc4640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
